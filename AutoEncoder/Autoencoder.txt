===============  Stacked autoencoder on Fashion MNIST ===============

## Using Keras to load the dataset

from tensorflow import keras
fashion_mnist = keras.datasets.fashion_mnist
(X_train_full, y_train_full), (X_test, y_test) = fashion_mnist.load_data()

print(X_train_full.shape)
print(X_test.shape)


## Create a validation set

X_valid, X_train = X_train_full[:5000]/255, X_train_full[5000:]/255



## Build a stacked autoencoder

stacked_encoder = keras.models.Sequential([
   keras.layers.Flatten(input_shape=[28, 28]),
   keras.layers.Dense(100, activation="selu"),
   keras.layers.Dense(30, activation="selu"),
])

stacked_decoder = keras.models.Sequential([
   keras.layers.Dense(100, activation="selu", input_shape=[30]),
   keras.layers.Dense(28 * 28, activation="sigmoid"),
   keras.layers.Reshape([28, 28])
])

stacked_ae = keras.models.Sequential([stacked_encoder, stacked_decoder])


## Compile the model

stacked_ae.compile(loss="binary_crossentropy", optimizer=keras.optimizers.SGD(learning_rate=1.5))


## Train the autoencoder

history = stacked_ae.fit(X_train, X_train, epochs=10, validation_data=[X_valid, X_valid])


## Reconstruction

X_train_recons = stacked_ae.predict(X_train)

X_valid_recons = stacked_ae.predict(X_valid)


## Visualize the images

import matplotlib.pyplot as plt

def plot_image(image):
   plt.imshow(image, cmap="binary")
   plt.axis("off")

def show_images(X, X_recons, n_images=5):
   fig = plt.figure(figsize=(n_images * 1.5, 3))
   for image_index in range(n_images):
      plt.subplot(2, n_images, 1 + image_index)
      plot_image(X[image_index])
      plt.subplot(2, n_images, 1 + n_images + image_index)
      plot_image(X_recons[image_index])


show_images(X_valid,X_valid_recons,n_images=5)

show_images(X_train,X_train_recons,n_images=5)



===============  Convolutional autoencoder ===============

## Build a convolutional autoencoder

conv_encoder = keras.models.Sequential([
   keras.layers.Reshape([28, 28, 1], input_shape=[28, 28]),
   keras.layers.Conv2D(16, kernel_size=3, padding="same", activation="selu"),
   keras.layers.MaxPool2D(pool_size=2),
   keras.layers.Conv2D(32, kernel_size=3, padding="same", activation="selu"),
   keras.layers.MaxPool2D(pool_size=2),
   keras.layers.Conv2D(64, kernel_size=3, padding="same", activation="selu"),
   keras.layers.MaxPool2D(pool_size=2)
])

conv_decoder = keras.models.Sequential([
   keras.layers.Conv2DTranspose(32, kernel_size=3, strides=2, padding="valid",
                      activation="selu",input_shape=[3, 3, 64]),
   keras.layers.Conv2DTranspose(16, kernel_size=3, strides=2, padding="same",activation="selu"),
   keras.layers.Conv2DTranspose(1, kernel_size=3, strides=2, padding="same",activation="sigmoid"),
   keras.layers.Reshape([28, 28])
])

conv_ae = keras.models.Sequential([conv_encoder, conv_decoder])



===============  Recurrent autoencoder ===============

## Build a recurrent autoencoder

recurrent_encoder = keras.models.Sequential([ 
     keras.layers.LSTM(100, return_sequences=True, input_shape=[None, 28]), 
     keras.layers.LSTM(30) ]) 

recurrent_decoder = keras.models.Sequential([
    keras.layers.RepeatVector(28, input_shape=[30]), 
    keras.layers.LSTM(100, return_sequences=True),
    keras.layers.TimeDistributed(keras.layers.Dense(28, activation="sigmoid")) ]) 

recurrent_ae = keras.models.Sequential([recurrent_encoder, recurrent_decoder])



===============  Denoise autoencoder with dropout ===============

## Build a denoise autoencoder with dropout

dropout_encoder = keras.models.Sequential([
    keras.layers.Flatten(input_shape=[28, 28]),
    keras.layers.Dropout(0.5),
    keras.layers.Dense(100, activation="selu"),
    keras.layers.Dense(30, activation="selu")
])

dropout_decoder = keras.models.Sequential([
    keras.layers.Dense(100, activation="selu", input_shape=[30]),
    keras.layers.Dense(28 * 28, activation="sigmoid"),
    keras.layers.Reshape([28, 28])
])

dropout_ae = keras.models.Sequential([dropout_encoder, dropout_decoder])



===============  Denoise autoencoder with Gaussian noise ===============

## Build a denoise autoencoder with Gaussian noise

denoise_encoder = keras.models.Sequential([
    keras.layers.Flatten(input_shape=[28, 28]),
    keras.layers.GaussianNoise(stddev=0.5),
    keras.layers.Dense(100, activation="selu"),
    keras.layers.Dense(30, activation="selu")
])

denoise_decoder = keras.models.Sequential([
    keras.layers.Dense(100, activation="selu", input_shape=[30]),
    keras.layers.Dense(28 * 28, activation="sigmoid"),
    keras.layers.Reshape([28, 28])
])

denoise_ae = keras.models.Sequential([denoise_encoder, denoise_decoder])



===============  Sparse autoencoder ===============

sparse_l1_encoder = keras.models.Sequential([
     keras.layers.Flatten(input_shape=[28, 28]),
     keras.layers.Dense(100, activation="selu"),
     keras.layers.Dense(300, activation="sigmoid"),
     keras.layers.ActivityRegularization(l1=1e-3)
])
sparse_l1_decoder = keras.models.Sequential([
     keras.layers.Dense(100, activation="selu", input_shape=[300]),
     keras.layers.Dense(28 * 28, activation="sigmoid"),
     keras.layers.Reshape([28, 28])
])

sparse_l1_ae = keras.models.Sequential([sparse_l1_encoder, sparse_l1_decoder])



===============  Variational autoencoder ===============

import tensorflow as tf
K = keras.backend
class Sampling(keras.layers.Layer):
   def call(self, inputs):
      mean, log_var = inputs
      return K.random_normal(tf.shape(log_var)) * K.exp(log_var / 2) + mean


## Build the encoder

codings_size = 10
inputs = keras.layers.Input(shape=[28, 28])
z = keras.layers.Flatten()(inputs)
z = keras.layers.Dense(150, activation="selu")(z)
z = keras.layers.Dense(100, activation="selu")(z)
codings_mean = keras.layers.Dense(codings_size)(z)      # μ
codings_log_var = keras.layers.Dense(codings_size)(z)    # γ
codings = Sampling()([codings_mean, codings_log_var])
variational_encoder = keras.Model(inputs=[inputs],
         outputs=[codings_mean, codings_log_var, codings])


## Build the decoder

decoder_inputs = keras.layers.Input(shape=[codings_size])
x = keras.layers.Dense(100, activation="selu")(decoder_inputs)
x = keras.layers.Dense(150, activation="selu")(x)
x = keras.layers.Dense(28 * 28, activation="sigmoid")(x)
outputs = keras.layers.Reshape([28, 28])(x)
variational_decoder = keras.Model(inputs=[decoder_inputs], outputs=[outputs])


## Build the variational autoencoder model

_, _, codings = variational_encoder(inputs)
reconstructions = variational_decoder(codings)
variational_ae = keras.Model(inputs=[inputs], outputs=[reconstructions])

latent_loss = -0.5 * K.sum(
     1 + codings_log_var - K.exp(codings_log_var) - K.square(codings_mean), axis=-1)
variational_ae.add_loss(K.mean(latent_loss) / 784.)


## Compile the model

variational_ae.compile(loss="binary_crossentropy", optimizer="rmsprop")


## Train the model

history = variational_ae.fit(X_train, X_train, epochs=50, batch_size=128,
validation_data=[X_valid, X_valid])



----------  Generating Fashion MNIST Images through the variational autoencoder ----------

codings = tf.random.normal(shape=[12, codings_size])
images = variational_decoder(codings).numpy()


def show_images_only(X, n_images):
   fig = plt.figure(figsize=(n_images * 1.5, 3))
   for image_index in range(n_images):
      plt.subplot(2, n_images, 1 + image_index)
      plot_image(X[image_index])


show_images_only(images,12)







