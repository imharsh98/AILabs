# Machine Learning notes:

## General Theory

-> Perceptron: 

-> SVM: polynomial kernel, 

-> DT:

-> RF:

-> ANN: multi-layer perceptron

-> Tips and Tricks:

-> CNN:
 terms: filters, stride, feature maps (same as filters/kernels??), 
 in convolution, when it is written as 9x9x24 (say) it means 24 filters of 9x9 size. As far as I understand, when we say filters and kernels we mean the same. 
 models which were covered include ResNet, LeNet, AlexNet. 

-> RNN

-> GAN and autoencoder

* Higher concepts after this (not covered in this course): Transformers, 

* What is meant by batch size?
    

## File structures

ANN.py:
    load the dataset


## How to read or understand the output:


HW1:
It is all SVM related. Checking the c-values and the different kernels which are needed.

HW2:
Decision Tree and Random Forest related.

## Folders in this repo

references: homework files from others
practice: some self-practice files
RNN: contains the files related to RNN like class lab
AudoEncoder: 
    this has separate files for style transfer as well as Generative Adversarial Networks
    Two files for style transfer are present. Not exactly sure about the difference between the two
CNN: CNN related files
Homeworks: contains all homeworks
    HW-6 -> only pdf file present. Can extract code from it and add to a notebook file.
SMIT-ML: files from ML course at SMIT
DTnRF:
ANN:
Perceptron: 
SVM:


